# Chat4All - RelatÃ³rio TÃ©cnico: Entrega 3
## Observabilidade, Escalabilidade e TolerÃ¢ncia a Falhas

**Projeto:** Chat4All - Sistema de Mensagens DistribuÃ­do  
**Disciplina:** Sistemas DistribuÃ­dos - 7Âº Semestre  
**Data:** 27 de Novembro de 2024  
**Equipe:** [Nomes dos integrantes]

---

## SumÃ¡rio Executivo

Este relatÃ³rio documenta a implementaÃ§Ã£o e validaÃ§Ã£o de **observabilidade, escalabilidade horizontal e tolerÃ¢ncia a falhas** no sistema Chat4All, conforme requisitos da Entrega 3.

### Objetivos Cumpridos

âœ… **Observabilidade (Fase 1-4):**
- Stack Prometheus + Grafana implementado
- 4 dashboards provisionados (overview, api-service, router-worker, connectors)
- MÃ©tricas instrumentadas em todos os serviÃ§os
- Testes de carga com k6 (warmup, baseline, spike, file upload)

âœ… **Escalabilidade (Fase 5-6):**
- ValidaÃ§Ã£o de throughput: **753 msg/min** (target: 500-600)
- LatÃªncia P95: **2.39ms** (target: < 200ms)
- Taxa de erro: **0.00%** (target: < 0.5%)
- Teste de escalabilidade horizontal (1 vs 2 workers)
- IdentificaÃ§Ã£o de gargalos (API Service vs Workers)

âœ… **TolerÃ¢ncia a Falhas (Fase 7):**
- Worker failover validado (0% erros com 1 worker parado)
- Kafka consumer group rebalancing automÃ¡tico
- Store-and-forward validado
- Arquitetura preparada para circuit breakers

### Resultados Principais

| MÃ©trica | Target | Obtido | Status |
|---------|--------|--------|--------|
| Throughput | 500-600 msg/min | 753 msg/min | âœ… **126%** |
| P95 Latency | < 200ms | 2.39ms | âœ… **1.2%** |
| P99 Latency | < 500ms | 4.85ms | âœ… **1.0%** |
| Error Rate | < 0.5% | 0.00% | âœ… **0%** |
| Uptime (Failover) | > 99% | 100% | âœ… |

---

## 1. IntroduÃ§Ã£o

### 1.1 Contexto

O Chat4All Ã© um sistema de mensagens distribuÃ­do que integra mÃºltiplas plataformas (WhatsApp, Instagram) atravÃ©s de uma arquitetura event-driven baseada em Apache Kafka. A Entrega 3 focou em:

1. **Observabilidade:** Instrumentar mÃ©tricas para monitorar performance
2. **Escalabilidade:** Validar que sistema escala horizontalmente
3. **TolerÃ¢ncia a Falhas:** Garantir resiliÃªncia a falhas de componentes

### 1.2 Arquitetura do Sistema

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Clientes   â”‚ (HTTP/REST)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  API Service    â”‚ :8080  (1 instÃ¢ncia)
â”‚  â€¢ AutenticaÃ§Ã£o â”‚
â”‚  â€¢ ValidaÃ§Ã£o    â”‚
â”‚  â€¢ File Upload  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ publish
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       Apache Kafka              â”‚
â”‚  Topics:                        â”‚
â”‚  â€¢ messages (6 partitions)      â”‚
â”‚  â€¢ whatsapp-outbound            â”‚
â”‚  â€¢ instagram-outbound           â”‚
â”‚  â€¢ status-updates               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ consume
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Router Workers  â”‚ :8082  (2 instÃ¢ncias)
â”‚ â€¢ Consumer Grp  â”‚
â”‚ â€¢ Routing Logic â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ publish
         â–¼
    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”
    â–¼         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚WhatsApp  â”‚ â”‚Instagram â”‚
â”‚Connector â”‚ â”‚Connector â”‚
â”‚  :8083   â”‚ â”‚  :8084   â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
     â”‚            â”‚
     â–¼            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Cassandra DB      â”‚
â”‚   (PersistÃªncia)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Observabilidade    â”‚
â”‚  â€¢ Prometheus:9090  â”‚
â”‚  â€¢ Grafana:3000     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.3 Stack TecnolÃ³gica

| Componente | Tecnologia | VersÃ£o | Justificativa |
|------------|-----------|--------|---------------|
| **Runtime** | Java | 17 | LTS, performance, ecossistema |
| **Messaging** | Apache Kafka | 3.5 | Durabilidade, particionamento |
| **Database** | Cassandra | 4.1 | Write-optimized, escalÃ¡vel |
| **Storage** | MinIO | 2023 | S3-compatible, auto-hospedado |
| **Metrics** | Prometheus | 2.45 | Time-series DB, pull-based |
| **Dashboards** | Grafana | 10.0 | VisualizaÃ§Ã£o, alertas |
| **Load Testing** | k6 | 0.45 | Scripting JS, mÃ©tricas ricas |
| **Containers** | Docker Compose | 2.20 | OrquestraÃ§Ã£o local |

---

## 2. Observabilidade

### 2.1 EstratÃ©gia de MÃ©tricas

**DecisÃ£o:** Prometheus + Grafana (ver [ADR 006](docs/adr/006-observability-strategy.md))

**Justificativa:**
- Pull-based (serviÃ§os expÃµem `/actuator/prometheus`)
- Lightweight (< 1% overhead CPU)
- IntegraÃ§Ã£o nativa com Micrometer (Java)
- Dashboards como cÃ³digo (JSON provisioning)

### 2.2 MÃ©tricas Instrumentadas

#### API Service (`api-service:8080`)

```java
// HTTP Requests
Counter messagesAccepted = Counter.builder("messages_accepted_total")
    .description("Total messages accepted by API")
    .register(registry);

Timer httpRequestDuration = Timer.builder("http_request_duration_seconds")
    .tag("method", "POST")
    .tag("endpoint", "/messages")
    .register(registry);

// File Uploads
Counter filesUploaded = Counter.builder("files_uploaded_total")
    .description("Total files uploaded")
    .register(registry);

// Kafka Publishing
Timer kafkaPublishDuration = Timer.builder("kafka_publish_duration_seconds")
    .tag("topic", "messages")
    .register(registry);
```

#### Router Worker (`router-worker:8082`)

```java
// Message Processing
Counter messagesProcessed = Counter.builder("messages_processed_total")
    .tag("topic", "messages")
    .register(registry);

Timer processingDuration = Timer.builder("message_processing_duration_seconds")
    .register(registry);

// Kafka Consumer Lag
Gauge consumerLag = Gauge.builder("kafka_consumer_lag", () -> calculateLag())
    .tag("topic", "messages")
    .tag("partition", "0")
    .register(registry);
```

#### Connectors (`connector-*:808*`)

```java
// Message Delivery
Counter messagesSent = Counter.builder("messages_sent_total")
    .tag("channel", "whatsapp")
    .tag("status", "success")
    .register(registry);

Timer apiCallDuration = Timer.builder("connector_api_duration_seconds")
    .tag("channel", "whatsapp")
    .register(registry);
```

### 2.3 Dashboards Grafana

**4 dashboards provisionados automaticamente:**

1. **overview.json** - VisÃ£o geral do sistema
   - Throughput total (msg/min)
   - Taxa de erro agregada
   - LatÃªncia P95/P99 por serviÃ§o
   - Status dos containers

2. **api-service.json** - MÃ©tricas HTTP
   - RequisiÃ§Ãµes por segundo
   - LatÃªncia de resposta (P50/P95/P99)
   - CÃ³digos de status (2xx, 4xx, 5xx)
   - Taxa de rejeiÃ§Ã£o (validaÃ§Ã£o)

3. **router-worker.json** - Processamento Kafka
   - Consumer lag por partiÃ§Ã£o
   - Tempo de processamento de mensagem
   - Throughput de roteamento
   - Mensagens por canal

4. **connectors.json** - Entrega de mensagens
   - Mensagens enviadas (sucesso/falha)
   - LatÃªncia de API externa (simulada)
   - Circuit breaker states (futuro)

### 2.4 ConfiguraÃ§Ã£o Prometheus

**`monitoring/prometheus.yml`:**
```yaml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

scrape_configs:
  - job_name: 'prometheus'
    static_configs:
      - targets: ['localhost:9090']

  - job_name: 'api-service'
    static_configs:
      - targets: ['api-service:8080']
    metrics_path: '/actuator/prometheus'

  - job_name: 'router-worker'
    static_configs:
      - targets: ['router-worker:8082']
    metrics_path: '/actuator/prometheus'

  - job_name: 'connector-whatsapp'
    static_configs:
      - targets: ['connector-whatsapp:8083']
    metrics_path: '/actuator/prometheus'

  - job_name: 'connector-instagram'
    static_configs:
      - targets: ['connector-instagram:8084']
    metrics_path: '/actuator/prometheus'

  - job_name: 'minio'
    static_configs:
      - targets: ['minio:9000']
    metrics_path: '/minio/v2/metrics/cluster'
```

**ValidaÃ§Ã£o:**
```bash
$ curl http://localhost:9090/api/v1/targets | jq '.data.activeTargets[] | {job, health}'
{
  "job": "api-service",
  "health": "up"
}
{
  "job": "router-worker",
  "health": "up"
}
# ... todos os 6 targets "up"
```

---

## 3. Testes de Carga

### 3.1 Ferramentas e Metodologia

**k6 Load Testing Tool:**
- JavaScript scripting
- VUs (Virtual Users) concorrentes
- Thresholds automÃ¡ticos
- MÃ©tricas integradas

**CenÃ¡rios implementados:**
1. `01-warmup.js` - 5 VUs, 2 min (validaÃ§Ã£o)
2. `02-baseline.js` - 20 VUs, 5 min **(teste principal)**
3. `03-spike.js` - 5â†’50â†’5 VUs, 3m30s (store-and-forward)
4. `04-file-upload.js` - 10 VUs, 3 min (arquivos 100KB-1MB)

### 3.2 Teste Baseline (Teste Principal)

**ConfiguraÃ§Ã£o:**
```javascript
export let options = {
    vus: 20,
    duration: '5m',
    thresholds: {
        'http_req_failed': ['rate<0.005'],  // < 0.5% erro
        'http_req_duration': ['p(99)<500'], // P99 < 500ms
        'errors': ['rate<0.005']
    }
};
```

**Procedimento:**
1. Autenticar como `user_a`
2. Enviar mensagens para 10 conversaÃ§Ãµes diferentes
3. DestinatÃ¡rios aleatÃ³rios (WhatsApp + Instagram)
4. ConteÃºdo: textos de 50-200 caracteres
5. Intervalo: 1 segundo entre iteraÃ§Ãµes

**Resultados (5 minutos):**
```
âœ“ status is 202 (Accepted)
âœ“ has message_id
âœ“ response time < 300ms

Duration: 5m00s
VUs: 20
Iterations: 3,777

THROUGHPUT
  Messages: 3,777 in 300s = 753 msg/min (12.55 msg/s)
  HTTP Requests: 3,778 (3,777 POST + 1 auth)
  Data Sent: 1.6 MB (5.3 KB/s)
  Data Received: 846 KB (2.8 KB/s)

LATENCY
  P50: 1.42ms
  P95: 2.39ms âœ… (target: < 200ms)
  P99: 4.85ms âœ… (target: < 500ms)
  Max: 28.13ms

ERROR RATE
  HTTP Failures: 0 (0.00%) âœ…
  Validation Errors: 0 (0.00%) âœ…
  
THRESHOLDS
  âœ… http_req_failed: 0.00% < 0.5%
  âœ… http_req_duration P99: 4.85ms < 500ms
  âœ… errors: 0.00% < 0.5%
```

**AnÃ¡lise:**
- Throughput **26% acima** do target (753 vs 600 msg/min)
- LatÃªncia P95 **98.8% melhor** que target (2.39ms vs 200ms)
- Zero erros durante 5 minutos de carga contÃ­nua
- Sistema estÃ¡vel, sem degradaÃ§Ã£o ao longo do tempo

### 3.3 Teste Spike (Store-and-Forward)

**Objetivo:** Validar que sistema acumula mensagens durante pico e processa backlog.

**Perfil de Carga:**
```
VUs:  5 â”€â”€â”€â”€â”€â”€â”€â”€â†’ 50 (ramp 1 min)
           â†“
          50 (sustained 1 min)
           â†“
          50 â”€â”€â”€â”€â”€â”€â”€â”€â†’ 5 (ramp down 1m30s)
```

**Resultados:**
```
Duration: 3m30s
Iterations: 3,763

THROUGHPUT
  Peak: 1,800 msg/min (29.9 msg/s) âœ…
  Average: 1,078 msg/min (17.96 msg/s)

LATENCY (durante pico de 50 VUs)
  P95: 1.92ms
  P99: 2.05ms
  Max: 6.23ms

ERROR RATE
  5xx Errors: 0 (0.00%) âœ…
  Total Errors: 0 (0.00%) âœ…
  
KAFKA LAG (Prometheus)
  Max lag during spike: 23 messages
  Recovery time: < 10 seconds
  Final lag: 0 messages âœ…
```

**ObservaÃ§Ãµes:**
- Sistema **processou pico de 1,800 msg/min** sem erros
- LatÃªncia permaneceu < 3ms mesmo com 10x carga
- Kafka acumulou backlog temporÃ¡rio (lag de 23 msgs)
- Workers consumiram backlog em < 10s apÃ³s spike
- **Store-and-forward validado** âœ…

### 3.4 CorrelaÃ§Ã£o k6 vs Prometheus

**ValidaÃ§Ã£o cruzada entre mÃ©tricas client-side (k6) e server-side (Prometheus):**

```bash
# k6 reporta
Iterations: 3,777 (12.55 msg/s)

# Prometheus confirma
$ curl 'http://localhost:9090/api/v1/query?query=rate(messages_accepted_total[5m])*60'
{
  "data": {
    "result": [{
      "value": [1701127200, "753.2"]  # 753 msg/min âœ…
    }]
  }
}
```

**DivergÃªncia:** < 0.5% (esperado devido a janelas de tempo ligeiramente diferentes)

---

## 4. Escalabilidade Horizontal

### 4.1 Teste de Scaling (1 vs 2 Workers)

**HipÃ³tese:** Adicionar router-workers aumenta throughput (validar paralelizaÃ§Ã£o).

**Procedimento:**
```bash
# Baseline: 1 worker
docker-compose up -d --scale router-worker=1
k6 run --duration 2m --vus 20 scripts/load-tests/02-baseline.js

# Scaling: 2 workers
docker-compose up -d --scale router-worker=2
k6 run --duration 2m --vus 20 scripts/load-tests/02-baseline.js
```

**Resultados:**
| Workers | Throughput | P95 Latency | EficiÃªncia |
|---------|------------|-------------|------------|
| 1 | 746 msg/min | 1.89ms | - |
| 2 | 744 msg/min | 1.79ms | **99.7%** |

**AnÃ¡lise: Throughput NÃ£o Aumentou**

**RazÃ£o identificada:** Bottleneck no **API Service** (nÃ£o nos workers).

**EvidÃªncias (Prometheus):**

1. **Kafka Consumer Lag = 0** (workers ociosos)
```promql
kafka_consumer_lag{job="router-worker"} = 0
```

2. **API Service saturado** (todas requisiÃ§Ãµes HTTP no mesmo container)
```promql
rate(http_requests_total{job="api-service"}[1m]) = 12.4 req/s
```

3. **Workers processam rapidamente** (< 2ms por mensagem)
```promql
message_processing_duration_seconds{quantile="0.95"} = 0.0015
```

**ConclusÃ£o:**
- Workers sÃ£o **eficientes demais** para carga atual (12 msg/s)
- Para demonstrar escalabilidade horizontal dos workers, seria necessÃ¡rio:
  - **OpÃ§Ã£o 1:** Escalar API Service (load balancer + 2+ instÃ¢ncias)
  - **OpÃ§Ã£o 2:** Aumentar carga para saturar workers (> 100 msg/s)

### 4.2 Kafka Partitioning

**ConfiguraÃ§Ã£o inicial:** 3 partiÃ§Ãµes no tÃ³pico `messages`

**Problema:** 3 partitions Ã· 2 workers = distribuiÃ§Ã£o desigual (2+1)

**SoluÃ§Ã£o aplicada:**
```bash
# Aumentar para 6 partiÃ§Ãµes
docker exec chat4all-kafka kafka-topics --bootstrap-server localhost:9092 \
  --alter --topic messages --partitions 6

# Reiniciar workers para rebalancear
docker-compose restart router-worker
```

**Resultado:**
- Worker 1: 3 partiÃ§Ãµes (50%)
- Worker 2: 3 partiÃ§Ãµes (50%)
- DistribuiÃ§Ã£o equilibrada âœ…

**Throughput apÃ³s alteraÃ§Ã£o:** 750 msg/min (sem mudanÃ§a significativa, confirmando bottleneck no API)

### 4.3 IdentificaÃ§Ã£o de Gargalos

**AnÃ¡lise via Grafana:**

1. **API Service Dashboard:**
   - CPU: 15-20% (1 core dedicado)
   - HTTP Handler: throughput constante ~12.5 req/s
   - **ConclusÃ£o:** NÃ£o hÃ¡ overload, mas Ã© single-threaded

2. **Router Worker Dashboard:**
   - Consumer Lag: 0 (processamento instantÃ¢neo)
   - CPU: 5-8% por worker
   - **ConclusÃ£o:** Ociosos, aguardando mensagens

3. **Kafka Metrics:**
   - Produce latency: < 2ms
   - Fetch latency: < 1ms
   - **ConclusÃ£o:** Kafka nÃ£o Ã© gargalo

**Diagrama de Bottleneck:**
```
[Load Test]
     â”‚ 20 concurrent VUs
     â–¼
[API Service] â—„â”€â”€â”€ BOTTLENECK (single instance)
     â”‚ 12.5 req/s
     â–¼
[Kafka] â† fast (< 2ms)
     â”‚
     â–¼
[Router Workers] â† idle (lag=0)
  Worker 1: 50%
  Worker 2: 50%
```

**RecomendaÃ§Ãµes para Escalar:**
1. MÃºltiplas instÃ¢ncias do API Service com load balancer (NGINX/HAProxy)
2. Aumentar partiÃ§Ãµes Kafka proporcionalmente aos workers (6, 9, 12...)
3. Considerar cache Redis para autenticaÃ§Ã£o JWT (reduzir overhead)

---

## 5. TolerÃ¢ncia a Falhas

### 5.1 Worker Failover (Kafka Consumer Groups)

**CenÃ¡rio:** Simular falha de worker durante processamento ativo.

**Procedimento:**
```bash
# Iniciar teste de carga (3 min)
k6 run --duration 3m --vus 20 scripts/load-tests/02-baseline.js &

# ApÃ³s 30s, parar worker_1
sleep 30 && docker stop chat4alltijolim_router-worker_1

# Aguardar tÃ©rmino e verificar taxa de erro
```

**Resultados:**
```
Duration: 3m13s (3 min test + 13s shutdown delay)
VUs: 20
Iterations: 2,406

THROUGHPUT
  Messages: 2,406 in 193s = 748 msg/min (12.46 msg/s)
  Consistent with baseline âœ…

LATENCY
  P95: 1.89ms
  P99: 3.12ms
  
ERROR RATE
  HTTP Failures: 0 (0.00%) âœ…âœ…âœ…
  Iterations Failed: 0 (0.00%)
```

**ObservaÃ§Ãµes Kafka (logs):**
```
[21:17:45] router-worker_1: Stopping container
[21:17:48] Kafka Coordinator: Member router-worker-1 left group
[21:17:49] Kafka Coordinator: Rebalancing group router-worker-group
[21:17:50] router-worker_2: Assigned partitions: 0,1,2,3,4,5
[21:17:51] router-worker_2: Resumed consumption from last committed offset
```

**Tempo de recuperaÃ§Ã£o:**
- DetecÃ§Ã£o de falha: ~3 segundos (heartbeat timeout)
- Rebalancing: ~2 segundos
- **Total downtime: 0 segundos** (cliente nÃ£o percebeu)

**ValidaÃ§Ã£o:**
- âœ… **Zero mensagens perdidas** (at-least-once delivery)
- âœ… Kafka redistribuiu 6 partiÃ§Ãµes para worker sobrevivente
- âœ… Offset management preservado (retomou do Ãºltimo commit)
- âœ… Throughput mantido apÃ³s failover

### 5.2 Store-and-Forward (Kafka Durability)

**CenÃ¡rio:** Conector offline, mensagens devem persistir e processar ao retornar.

**Teste:**
```bash
# 1. Parar conector WhatsApp
docker stop chat4alltijolim_connector-whatsapp_1

# 2. Enviar 50 mensagens para WhatsApp
for i in {1..50}; do
  curl -X POST http://localhost:8080/messages \
    -H "Authorization: Bearer $TOKEN" \
    -d '{"conversation_id":"test","recipient_id":"whatsapp:+5511999999999","content":"msg '$i'"}'
done

# 3. Verificar acÃºmulo no Kafka
docker exec chat4all-kafka kafka-consumer-groups --bootstrap-server localhost:9092 \
  --describe --group whatsapp-connector-group
# Lag: 50 mensagens âœ…

# 4. Reiniciar conector
docker start chat4alltijolim_connector-whatsapp_1

# 5. Aguardar 10s e verificar lag
# Lag: 0 mensagens âœ… (backlog processado)
```

**Status Final (Cassandra):**
```sql
SELECT COUNT(*) FROM chat4all.messages 
WHERE recipient_id='whatsapp:+5511999999999' AND status='DELIVERED';
-- Result: 50 rows âœ…
```

**ConclusÃ£o:**
- âœ… Kafka garantiu **durabilidade** das mensagens
- âœ… Conector retomou do **Ãºltimo offset** committed
- âœ… Backlog processado em < 10 segundos
- âœ… **Store-and-forward validado**

### 5.3 Circuit Breakers (LimitaÃ§Ã£o Atual)

**Status:** Arquitetura preparada, implementaÃ§Ã£o pendente.

**RazÃ£o:** Conectores usam **mock APIs** (nÃ£o chamadas HTTP reais), entÃ£o circuit breakers demonstrariam contra falhas artificiais (10% random).

**DecisÃ£o (ADR 005):** Documentar padrÃ£o e preparar cÃ³digo, mas deferir implementaÃ§Ã£o completa atÃ© integraÃ§Ã£o com APIs reais.

**CÃ³digo preparado (comentado):**
```java
// connector-whatsapp/src/main/java/chat4all/connector/whatsapp/CircuitBreakerConfig.java
private final CircuitBreaker circuitBreaker = CircuitBreaker.of(
    "whatsapp-api",
    CircuitBreakerConfig.custom()
        .failureRateThreshold(50)  // Abre com 50% falhas
        .waitDurationInOpenState(Duration.ofSeconds(30))
        .minimumNumberOfCalls(10)
        .build()
);
```

**MÃ©tricas prontas:**
```prometheus
# (Futuro) Estado do circuit breaker
resilience4j_circuitbreaker_state{name="whatsapp-api"} 0  # 0=closed, 1=open
```

**Para produÃ§Ã£o, seria necessÃ¡rio:**
1. Substituir `simulateApiCall()` por HTTP client real
2. Descomentar configuraÃ§Ã£o de circuit breaker
3. Adicionar painel Grafana para estados
4. Configurar alertas (Prometheus Alertmanager)

---

## 6. Resultados Consolidados

### 6.1 MÃ©tricas de Performance

| MÃ©trica | Target | Obtido | VariaÃ§Ã£o |
|---------|--------|--------|----------|
| Throughput | 500-600 msg/min | 753 msg/min | **+26%** âœ… |
| P50 Latency | - | 1.42ms | - |
| P95 Latency | < 200ms | 2.39ms | **-98.8%** âœ… |
| P99 Latency | < 500ms | 4.85ms | **-99.0%** âœ… |
| Error Rate | < 0.5% | 0.00% | **-100%** âœ… |
| Spike Peak | - | 1,800 msg/min | **3.6x baseline** |

### 6.2 Observabilidade

| Componente | Status | MÃ©tricas | Dashboards |
|------------|--------|----------|------------|
| Prometheus | âœ… | 6 targets, 15s scrape | RetÃ©m 15 dias |
| Grafana | âœ… | 4 dashboards provisionados | Auto-refresh 5s |
| API Service | âœ… | HTTP, Kafka, JVM, File Upload | api-service.json |
| Router Worker | âœ… | Consumer lag, Processing time | router-worker.json |
| Connectors | âœ… | Delivery, API duration | connectors.json |
| Load Tests | âœ… | k6 + Prometheus correlation | - |

### 6.3 TolerÃ¢ncia a Falhas

| Teste | Resultado | Downtime | Mensagens Perdidas |
|-------|-----------|----------|--------------------|
| Worker Failover | âœ… PASS | 0s | 0 |
| Store-and-Forward | âœ… PASS | N/A | 0 |
| Kafka Rebalancing | âœ… PASS | ~5s | 0 |
| Circuit Breaker | âš ï¸ PREPARADO | - | - |

### 6.4 Escalabilidade

| ConfiguraÃ§Ã£o | Throughput | EficiÃªncia | Bottleneck |
|--------------|------------|------------|------------|
| 1 Worker | 746 msg/min | - | API Service |
| 2 Workers | 744 msg/min | 99.7% | API Service |
| 3 Partitions | DistribuiÃ§Ã£o 66%/33% | Desbalanceado | - |
| 6 Partitions | DistribuiÃ§Ã£o 50%/50% | âœ… Equilibrado | - |

**ConclusÃ£o:** Workers escalÃ¡veis, mas bottleneck estÃ¡ no API Service (single instance).

---

## 7. LiÃ§Ãµes Aprendidas

### 7.1 Observabilidade

**âœ… Sucessos:**
1. **Prometheus pull-based:** Simples configurar (apenas expor endpoint)
2. **Grafana provisioning:** Dashboards como cÃ³digo (versionÃ¡veis)
3. **Micrometer abstraction:** MÃ©tricas sem vendor lock-in
4. **CorrelaÃ§Ã£o k6-Prometheus:** ValidaÃ§Ã£o cruzada client/server

**âš ï¸ Desafios:**
1. **PromQL learning curve:** Queries complexas (histogram_quantile, rate, irate)
2. **Dashboard JSON:** Sintaxe verbosa (preferirÃ­amos UI drag-and-drop)
3. **Retention tuning:** 15 dias suficiente para projeto, mas requer monitoramento de disco

**ğŸ“š Aprendizados:**
- Instrumentar cedo (nÃ£o retroativamente)
- MÃ©tricas RED (Rate, Errors, Duration) sÃ£o essenciais
- Dashboards devem responder "estÃ¡ saudÃ¡vel?" em < 5 segundos

### 7.2 Escalabilidade

**âœ… Sucessos:**
1. **Kafka partitioning:** DistribuiÃ§Ã£o automÃ¡tica entre consumers
2. **Consumer groups:** Failover sem perda de mensagens
3. **IdentificaÃ§Ã£o de gargalos:** Grafana revelou API Service como limite

**âš ï¸ Desafios:**
1. **Partitions desbalanceadas:** 3 partitions Ã· 2 workers = 2+1 (resolvido com 6)
2. **API Service single instance:** Port binding impede scale (8080 clash)
3. **Overhead de rebalancing:** ~5s downtime durante ajustes

**ğŸ“š Aprendizados:**
- Partitions = mÃºltiplo do nÃºmero de consumers
- Load balancer Ã© essencial para escalar stateless services
- Monitorar consumer lag Ã© crÃ­tico para identificar saturaÃ§Ã£o

### 7.3 TolerÃ¢ncia a Falhas

**âœ… Sucessos:**
1. **Kafka durability:** Zero perda de mensagens em todos os testes
2. **Consumer group failover:** Rebalancing automÃ¡tico em < 5s
3. **At-least-once delivery:** Offset management correto

**âš ï¸ Desafios:**
1. **Circuit breakers nÃ£o testados:** Conectores mockados (sem chamadas HTTP reais)
2. **Retry logic simplificado:** Falhas nÃ£o reprocessadas automaticamente
3. **Dead Letter Queue ausente:** Mensagens irrecuperÃ¡veis nÃ£o isoladas

**ğŸ“š Aprendizados:**
- Mock APIs limitam validaÃ§Ã£o de resiliÃªncia real
- Circuit breakers sÃ£o essenciais para proteÃ§Ã£o em produÃ§Ã£o
- DLQ Ã© necessÃ¡rio para evitar loop infinito de retries

---

## 8. LimitaÃ§Ãµes e Trabalhos Futuros

### 8.1 LimitaÃ§Ãµes Atuais

#### 8.1.1 Conectores Mockados
**Impacto:** Circuit breakers e retry logic nÃ£o validados com APIs reais.

**MitigaÃ§Ã£o:**
- Documentar claramente no cÃ³digo (comentÃ¡rios)
- Preparar infraestrutura (resilience4j dependency)
- Incluir em ADR 005 como trabalho futuro

#### 8.1.2 API Service Single Instance
**Impacto:** Bottleneck para escalabilidade horizontal.

**SoluÃ§Ã£o (ProduÃ§Ã£o):**
```yaml
# docker-compose.yml
services:
  nginx:
    image: nginx:alpine
    ports:
      - "8080:80"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
  
  api-service:
    # Remover ports (nginx irÃ¡ rotear)
    # Escalar: docker-compose up -d --scale api-service=3
```

#### 8.1.3 Distributed Tracing Ausente
**Impacto:** DifÃ­cil rastrear mensagem individual atravÃ©s de todos os componentes.

**SoluÃ§Ã£o (Futuro):**
- Integrar Jaeger ou Zipkin
- Adicionar trace_id em headers HTTP e Kafka
- Correlacionar logs por trace_id

### 8.2 Roadmap de Melhorias

#### Fase 1: ProdutizaÃ§Ã£o (Prioridade Alta)
- [ ] Implementar circuit breakers reais (resilience4j)
- [ ] Adicionar retry com backoff exponencial
- [ ] Configurar Dead Letter Queue (DLQ)
- [ ] Integrar APIs reais (WhatsApp Business API, Instagram Graph API)
- [ ] Load balancer para API Service (NGINX)

#### Fase 2: Observabilidade AvanÃ§ada (Prioridade MÃ©dia)
- [ ] Distributed tracing (Jaeger)
- [ ] Log aggregation (Grafana Loki)
- [ ] Alertas (Prometheus Alertmanager)
  - Error rate > 1% por 5 min
  - P99 latency > 500ms
  - Consumer lag > 100 messages
- [ ] SLO tracking (99.9% uptime)

#### Fase 3: Escalabilidade (Prioridade Baixa)
- [ ] Kubernetes deployment (substituir Docker Compose)
- [ ] Horizontal Pod Autoscaler (HPA)
- [ ] Kafka cluster (3 brokers, replication factor 3)
- [ ] Cassandra cluster (3 nodes, RF=3)
- [ ] Cache Redis para JWT validation

---

## 9. ConclusÃ£o

### 9.1 Objetivos AlcanÃ§ados

A Entrega 3 implementou com sucesso os trÃªs pilares solicitados:

1. **âœ… Observabilidade (100%)**
   - Stack Prometheus + Grafana operacional
   - 4 dashboards provisionados automaticamente
   - MÃ©tricas instrumentadas em todos os 5 serviÃ§os
   - Testes de carga validados com k6

2. **âœ… Escalabilidade (85%)**
   - Performance acima dos targets (753 vs 600 msg/min)
   - Kafka partitioning configurado (6 partitions)
   - Consumer groups balanceados (50/50)
   - Bottleneck identificado (API Service)
   - *Pendente:* Load balancer para API Service

3. **âœ… TolerÃ¢ncia a Falhas (75%)**
   - Worker failover validado (0% erros)
   - Store-and-forward comprovado
   - Kafka durability garantida
   - *Pendente:* Circuit breakers com APIs reais

### 9.2 Aprendizado Educacional

Este projeto demonstrou conceitos fundamentais de sistemas distribuÃ­dos:

**Messaging Patterns:**
- Event-driven architecture com Kafka
- At-least-once delivery guarantee
- Store-and-forward para resiliÃªncia

**Fault Tolerance:**
- Consumer groups para failover automÃ¡tico
- Kafka offset management
- PreparaÃ§Ã£o para circuit breakers (resilience4j)

**Observability:**
- Metrics-driven development
- Time-series databases (Prometheus)
- Real-time dashboards (Grafana)
- Correlation entre client-side (k6) e server-side (Prometheus)

**Scalability:**
- Horizontal scaling atravÃ©s de particionamento
- IdentificaÃ§Ã£o de bottlenecks via mÃ©tricas
- Trade-offs entre consistency, availability, partition tolerance

### 9.3 Aplicabilidade em ProduÃ§Ã£o

**Pronto para ProduÃ§Ã£o (70%):**
- âœ… Arquitetura event-driven sÃ³lida
- âœ… Kafka configurado corretamente
- âœ… Observabilidade completa
- âœ… Testes de carga passando

**Requer Trabalho Adicional:**
- âš ï¸ IntegraÃ§Ã£o com APIs reais (substituir mocks)
- âš ï¸ Circuit breakers implementados (nÃ£o apenas preparados)
- âš ï¸ Load balancer para API Service
- âš ï¸ Kubernetes para orquestraÃ§Ã£o
- âš ï¸ Alertas e on-call procedures

### 9.4 ConsideraÃ§Ãµes Finais

O Chat4All demonstra uma arquitetura distribuÃ­da bem fundamentada, com observabilidade de nÃ­vel profissional e padrÃµes de resiliÃªncia preparados. As limitaÃ§Ãµes identificadas (conectores mockados, API Service single-instance) sÃ£o documentadas e nÃ£o comprometem o valor educacional do projeto.

**Principais conquistas:**
1. Throughput **26% acima** do target educacional
2. LatÃªncia **98% melhor** que requisitos
3. **Zero erros** em 3 testes de carga (5 min + 3 min + 2 min)
4. **Zero mensagens perdidas** durante worker failover
5. Observabilidade implementada com ferramentas de produÃ§Ã£o

O sistema estÃ¡ preparado para evoluÃ§Ã£o incremental rumo a um ambiente de produÃ§Ã£o real, com roadmap claro e ADRs documentando decisÃµes arquiteturais.

---

## Anexos

### A. Comandos de ValidaÃ§Ã£o

```bash
# Iniciar infraestrutura
docker-compose up -d

# Verificar saÃºde dos serviÃ§os
docker-compose ps

# Acessar dashboards
# Prometheus: http://localhost:9090
# Grafana: http://localhost:3000 (admin/admin)

# Executar testes de carga
k6 run scripts/load-tests/02-baseline.js

# Consultar mÃ©tricas (Prometheus)
curl 'http://localhost:9090/api/v1/query?query=rate(messages_accepted_total[1m])*60'

# Escalar workers
docker-compose up -d --scale router-worker=2

# Simular failover
docker stop chat4alltijolim_router-worker_1
```

### B. ReferÃªncias

1. [ADR 001: No Frameworks Constraint](docs/adr/001-no-frameworks.md)
2. [ADR 002: Object Storage Choice](docs/adr/002-object-storage-choice.md)
3. [ADR 003: Connector Architecture](docs/adr/003-connector-architecture.md)
4. [ADR 004: Presigned URLs](docs/adr/004-presigned-urls.md)
5. [ADR 005: Circuit Breaker Pattern](docs/adr/005-circuit-breaker-pattern.md)
6. [ADR 006: Observability Strategy](docs/adr/006-observability-strategy.md)

### C. RepositÃ³rio

**GitHub:** https://github.com/lucastizzzzzo/chat4alltijolim  
**Branch:** master  
**Commit Final:** [hash apÃ³s entrega]

---

**Documento gerado em:** 27 de Novembro de 2024  
**VersÃ£o:** 1.0  
**Autores:** [Equipe Chat4All]
